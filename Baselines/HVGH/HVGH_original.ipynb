{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4P6_UboLT5Kq"
   },
   "source": [
    "### Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o9zhZgN5T2XC"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-08 15:32:27.049962: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory\n",
      "2022-04-08 15:32:27.050021: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory\n",
      "2022-04-08 15:32:27.050027: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "#VAE\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import time\n",
    "\n",
    "#HDP-GP-HSMM\n",
    "import random\n",
    "import math\n",
    "import sys\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "M6f4WnrtVk4R",
    "outputId": "42665bee-e32d-4db7-a70c-d3d1165df823"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "print (tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Op4cGV1HoGza"
   },
   "source": [
    "### VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g_jAbb2LUV6Q"
   },
   "outputs": [],
   "source": [
    "class Variational_Auto_Encoder():\n",
    "  def __init__(self, input_dim, hidden_dims, latent_dim, kld_weight, epochs):\n",
    "    self.input_dim = input_dim\n",
    "    self.latent_dim = latent_dim\n",
    "    self.hidden_encoder_dim1 = hidden_dims[0]\n",
    "    self.hidden_encoder_dim2 = hidden_dims[1]\n",
    "    self.hidden_decoder_dim1 = hidden_dims[2]\n",
    "    self.hidden_decoder_dim2 = hidden_dims[3]\n",
    "    self.kld_weight = kld_weight\n",
    "    self.opt = Adam(lr=0.0001)\n",
    "    self.epochs = epochs\n",
    "\n",
    "    #encoder\n",
    "    logvar_prior = tf.keras.Input(shape=(self.latent_dim, ), name='logvar_prior')\n",
    "    mu_prior = tf.keras.Input(shape=(self.latent_dim, ), name='mu_prior')\n",
    "    inputs = tf.keras.layers.Input(shape=(self.input_dim, ), name='encoder_input')\n",
    "    hidden1= tf.keras.layers.Dense(self.hidden_encoder_dim1, activation='relu', name='enc1') (inputs)\n",
    "    hidden2 = tf.keras.layers.Dense(self.hidden_encoder_dim2, activation='relu', name='enc2') (hidden1)\n",
    "    z_mean = tf.keras.layers.Dense(self.latent_dim, activation='linear', name='z_mean')(hidden2)\n",
    "    z_log_var= tf.keras.layers.Dense(self.latent_dim, activation='linear', name='z_log_var')(hidden2)\n",
    "    z = tf.keras.layers.Lambda(self.sampling, name='z')([z_mean, z_log_var])\n",
    "    \n",
    "    enc_outputs = [z_mean, z_log_var, z]\n",
    "    encoder = tf.keras.models.Model(inputs, enc_outputs, name='encoder')\n",
    "\n",
    "    #decoder\n",
    "    latent_inputs = tf.keras.layers.Input(shape=(self.latent_dim,), name='z_sampling')\n",
    "    dec_hidden1 = tf.keras.layers.Dense(self.hidden_decoder_dim1, activation='relu', name='dec1') (latent_inputs)\n",
    "    dec_hidden2 = tf.keras.layers.Dense(self.hidden_decoder_dim2, activation='relu', name='dec2') (dec_hidden1)\n",
    "    outputs = tf.keras.layers.Dense(self.input_dim, activation='sigmoid') (dec_hidden2)\n",
    "\n",
    "    decoder = tf.keras.models.Model(latent_inputs, outputs, name='decoder')\n",
    "\n",
    "    #VAE(encoder+decoder)\n",
    "    inputs_ = [inputs, logvar_prior, mu_prior]\n",
    "    outputs_ = [ decoder(encoder(inputs)[2]), encoder(inputs)[0], encoder(inputs)[1] , encoder(inputs)[2]]  #output, mu, sigma\n",
    "    self.VAE = tf.keras.models.Model(inputs_, outputs_, name='VAE')\n",
    "    \n",
    "    #Loss\n",
    "    MSE = tf.reduce_sum( tf.math.squared_difference(K.flatten(outputs_[0]), K.flatten(inputs_[0])))\n",
    "    KLD = - 0.5 * tf.reduce_sum(1 + logvar_prior + z_log_var\n",
    "            - (tf.pow(z_mean - mu_prior, 2) \n",
    "            + tf.exp(z_log_var))/tf.exp(logvar_prior))\n",
    "    loss = tf.reduce_mean(MSE + KLD * self.kld_weight )\n",
    "\n",
    "    self.VAE.add_loss(loss)\n",
    "\n",
    "  def sampling(self, args):\n",
    "    z_mean, z_log_var = args\n",
    "    batch = K.shape(z_mean)[0]\n",
    "    dim = K.int_shape(z_mean)[1]\n",
    "    epsilon = K.random_normal(shape=(batch, dim))\n",
    "    \n",
    "    return z_mean + K.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "  def compile(self):\n",
    "    self.VAE.compile(optimizer=self.opt)\n",
    "    #print (self.VAE.summary())\n",
    "\n",
    "  def learn(self, data, logvar_prior, mu_prior, verbose=True):\n",
    "    result = self.VAE.fit([data, logvar_prior, mu_prior] , epochs=1, verbose=verbose)\n",
    "    return result\n",
    "\n",
    "  def predict(self, data, logvar_prior, mu_prior, losses=False):\n",
    "    reconst, mu, sigma, z = self.VAE.predict([data, logvar_prior, mu_prior])\n",
    "    return reconst, mu, sigma, z\n",
    "\n",
    "  def plot(self, data, reconst, mu, sigma, z, losses, savepath):\n",
    "    if losses != False:\n",
    "      plt.title('loss')\n",
    "      plt.plot(np.arange(self.epochs), losses)\n",
    "      plt.savefig(savepath+'_loss.png')\n",
    "      plt.close()\n",
    "\n",
    "    plt.title(\"z_alldim\")\n",
    "    plt.plot(np.arange(mu.shape[0]), mu)\n",
    "    plt.savefig(savepath+'_z.png')\n",
    "    plt.close()\n",
    "\n",
    "    plt.title(\"z_hat_alldim\")\n",
    "    plt.plot(np.arange(mu.shape[0]), z)\n",
    "    plt.savefig(savepath+'_z_hat.png')\n",
    "    plt.close()\n",
    "\n",
    "    plt.title('data_alldim')\n",
    "    plt.plot(np.arange(mu.shape[0]), data)\n",
    "    plt.savefig(savepath+'_oridata.png')\n",
    "    plt.close()\n",
    "\n",
    "    plt.title('reconst_alldim')\n",
    "    plt.plot(np.arange(mu.shape[0]), reconst)\n",
    "    plt.savefig(savepath+'_reconst.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v8MoFn55VSQ5"
   },
   "source": [
    "### GaussianProcess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "seXBh3ADUy3T"
   },
   "outputs": [],
   "source": [
    "%load_ext Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K7NUmCGtU00V"
   },
   "outputs": [],
   "source": [
    "%%cython\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cdef extern from \"math.h\":\n",
    "    double exp(double)\n",
    "    double sqrt(double)\n",
    "    double log(double)\n",
    "\n",
    "cdef class GP:\n",
    "    cdef double beta\n",
    "    cdef int ns\n",
    "    cdef xt, yt\n",
    "    cdef double[:,:] i_cov\n",
    "    cdef double[:] param\n",
    "    cdef dict param_cache\n",
    "\n",
    "    cdef double covariance_func(self, double xi, double xj):\n",
    "        cdef double theta0 = 1.0\n",
    "        cdef double theta1 = 1.0\n",
    "        cdef double theta2 = 0\n",
    "        cdef double theta3 = 16.0\n",
    "        return theta0 * exp(-0.5 * theta1 * (xi - xj) * (xi - xj)) + theta2 + theta3 * xi * xj\n",
    "    \n",
    "    cdef double normpdf(self, double x, double mu, double sigma):\n",
    "        return 1./(sqrt(2*np.pi)*sigma)*exp(-0.5 * ((x - mu)/sigma)**2)\n",
    "\n",
    "    def __init__( self ):\n",
    "        self.beta = 10.0\n",
    "        self.param_cache = {}\n",
    "\n",
    "    def learn(self, xt, yt ):\n",
    "        cdef int i, j\n",
    "        self.xt = xt\n",
    "        self.yt = yt\n",
    "        self.ns = len(xt)\n",
    "\n",
    "        cdef double[:,:] cov = np.zeros((self.ns, self.ns))\n",
    "\n",
    "        for i in range(self.ns):\n",
    "            for j in range(self.ns):\n",
    "                cov[i,j] = self.covariance_func(xt[i], xt[j])\n",
    "                if i==j:\n",
    "                    cov[i,j] += 1/self.beta\n",
    "\n",
    "        self.i_cov = np.linalg.inv(cov)\n",
    "        self.param = np.dot(self.i_cov, self.yt)\n",
    "        self.param_cache.clear()\n",
    "\n",
    "    def plot(self, x):\n",
    "        mus, sigmas = self.predict( x.reshape(-1,1) )\n",
    "        plt.plot( x, mus )\n",
    "        \n",
    "        y_max = mus + np.sqrt(sigmas.flatten())\n",
    "        y_min = mus - np.sqrt(sigmas.flatten())\n",
    "\n",
    "        plt.fill_between(x, y_min, y_max, facecolor=\"lavender\" , alpha=0.9 , edgecolor=\"lavender\"  )\n",
    "        plt.plot(self.xt, self.yt)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    def predict( self, x ):\n",
    "        mus = []\n",
    "        sigmas = []\n",
    "        n = len(x)\n",
    "        tt = [y - np.random.normal() / self.beta for y in self.yt]\n",
    "        for k in range(n):\n",
    "            v = np.zeros((self.ns))\n",
    "            for i in range(self.ns):\n",
    "                v[i] = self.covariance_func(x[k], self.xt[i])\n",
    "            c = self.covariance_func(x[k], x[k]) + 1.0 / self.beta\n",
    "            \n",
    "            mu = np.dot(v, np.dot(self.i_cov, tt))\n",
    "            sigma = c - np.dot(v, np.dot(self.i_cov, v))\n",
    "            \n",
    "            mus.append(mu)\n",
    "            sigmas.append(sigma)\n",
    "        \n",
    "        return np.array(mus), np.array(sigmas)\n",
    "    \n",
    "\n",
    "    cpdef double calc_lik_al( self, double[:] xs, double[:] ys ):\n",
    "        cdef int k,i\n",
    "        cdef int n = len(xs)\n",
    "        cdef double lik = 0\n",
    "        cdef int ns = self.ns\n",
    "        cdef double c,p,mu,sigma\n",
    "        cdef double[:] v= np.zeros((ns))\n",
    "\n",
    "        for k in range(n):\n",
    "            # 計算結果をキャッシュして使い回す\n",
    "            if xs[k] in self.param_cache:\n",
    "                mu, sigma = self.param_cache[ xs[k] ]\n",
    "            else:\n",
    "                v = np.zeros((ns))\n",
    "                for i in range(ns):\n",
    "                    v[i] = self.covariance_func(xs[k], self.xt[i])\n",
    "                c = self.covariance_func(xs[k], xs[k]) + 1.0 / self.beta\n",
    "                mu = np.dot(v, self.param)\n",
    "                sigma = c - np.dot(v, np.dot(self.i_cov, v))\n",
    "                \n",
    "                self.param_cache[ xs[k] ] = (mu, sigma)\n",
    "\n",
    "            p = self.normpdf( ys[k] , mu, sigma )\n",
    "            if p<=0:\n",
    "                p = 0.000000000001\n",
    "            lik += log( p )\n",
    "\n",
    "        return lik\n",
    "\n",
    "\n",
    "    def calc_lik( self, xs, ys ):\n",
    "      lik = self.calc_lik_al( xs, ys )\n",
    "      return lik"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WTHGGvRRaUFb"
   },
   "source": [
    "### logsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tmlzDvM2aV6T"
   },
   "outputs": [],
   "source": [
    "%%cython\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.mlab as mlab\n",
    "import sys\n",
    "\n",
    "cdef extern from \"math.h\":\n",
    "    double log(double)\n",
    "    double exp(double)\n",
    "\n",
    "\n",
    "cpdef logsumexp( double[:,:] a ):\n",
    "    cdef double max_val = -sys.float_info.max\n",
    "    cdef double sum_exp = 0\n",
    "    cdef int I = a.shape[0]\n",
    "    cdef int J = a.shape[1]\n",
    "    \n",
    "    for i in range(I):\n",
    "        for j in range(J):\n",
    "            if max_val<a[i,j]:\n",
    "                max_val = a[i,j]\n",
    "                \n",
    "    for i in range(I):\n",
    "        for j in range(J):\n",
    "            sum_exp += exp( a[i,j] - max_val )\n",
    "    return log(sum_exp) + max_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pAbp3HAOWnVW"
   },
   "source": [
    "### multidim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a8FhZCwMWp0d"
   },
   "outputs": [],
   "source": [
    "class GPMD:\n",
    "    def __init__(self, dim):\n",
    "        self.__dim = dim\n",
    "        self.__gp = [ GP() for d in range(self.__dim) ]\n",
    "\n",
    "    def learn(self,x, y ):\n",
    "        y = np.array(y, dtype=np.float).reshape( (-1,self.__dim) )\n",
    "        x = np.array(x,dtype=np.float)\n",
    "\n",
    "        for d in range(self.__dim):\n",
    "            if len(y)!=0:\n",
    "                self.__gp[d].learn( x, y[:,d] )\n",
    "            else:\n",
    "                self.__gp[d].learn( x, [] )\n",
    "\n",
    "\n",
    "    def calc_lik(self, x, y, last = False):\n",
    "        lik = 0.0\n",
    "        mus = []\n",
    "        sigmas = []\n",
    "\n",
    "        if self.__dim==1:\n",
    "            y = np.asarray(y, dtype=np.float).reshape( (-1,self.__dim) )\n",
    "        for d in range(self.__dim):\n",
    "            lik += self.__gp[d].calc_lik( x , y[:,d] )\n",
    "            if last != False:\n",
    "              mu , sig = self.__gp[d].predict(x)\n",
    "              mus.append(mu)\n",
    "              sigmas.append(sig)\n",
    "\n",
    "        if last != False:\n",
    "          return lik, np.array(mus), np.array(sigmas)\n",
    "        else:\n",
    "          return lik\n",
    "\n",
    "    def plot(self, x ):\n",
    "        for d in range(self.__dim):\n",
    "            plt.subplot( self.__dim, 1, d+1 )\n",
    "\n",
    "            mus, sigmas = self.__gp[d].predict(x)\n",
    "            y_min = mus - sigmas*2\n",
    "            y_max = mus + sigmas*2\n",
    "\n",
    "            plt.fill_between( x, y_min, y_max, facecolor=\"lavender\" , alpha=0.9 , edgecolor=\"lavender\"  )\n",
    "            plt.plot(x, y_min, 'b--')\n",
    "            plt.plot(x, mus, 'b-')\n",
    "            plt.plot(x, y_max, 'b--')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2ibGl4zBWqVg"
   },
   "source": [
    "### segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-0BfwNmBWtc9"
   },
   "outputs": [],
   "source": [
    "class GPSegmentation():\n",
    "    def __init__(self, dim, gamma, alpha, initial_class):\n",
    "        self.dim = dim\n",
    "        self.numclass = initial_class\n",
    "        self.segmlen = 3\n",
    "        self.gps = [ GPMD(dim) for i in range(self.numclass) ]\n",
    "        self.segm_in_class= [ [] for i in range(self.numclass) ]\n",
    "        self.segmclass = {}\n",
    "        self.segments = []\n",
    "        self.trans_prob = np.ones( (1,1) )\n",
    "        self.trans_prob_bos = np.ones( 1 )\n",
    "        self.trans_prob_eos = np.ones( 1 )\n",
    "        self.all_numclass = []\n",
    "        self.counter = 0\n",
    "        self.is_initialized = False\n",
    "        \n",
    "        # parameters\n",
    "        self.MAX_LEN = 20\n",
    "        self.MIN_LEN = 3\n",
    "        self.AVE_LEN = 12\n",
    "        self.SKIP_LEN = 1\n",
    "\n",
    "        self.alpha = alpha\n",
    "        self.beta = np.ones(1)\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def load_data(self, zs, classfile=None ):\n",
    "        self.data = []\n",
    "        self.segments = []\n",
    "        self.is_initialized = False\n",
    "\n",
    "        for y in zs:\n",
    "            segm = []\n",
    "            self.data.append( np.array(y, dtype=np.float) )\n",
    "\n",
    "            i = 0\n",
    "            while i<len(y):\n",
    "                length = random.randint(self.MIN_LEN, self.MAX_LEN)\n",
    "\n",
    "                if i+length+1>=len(y):\n",
    "                    length = len(y)-i\n",
    "\n",
    "                segm.append( y[i:i+length+1] )\n",
    "\n",
    "                i+=length\n",
    "\n",
    "            self.segments.append( segm )\n",
    "\n",
    "            for i,s in enumerate(segm):\n",
    "                c = random.randint(0,self.numclass-1)\n",
    "                self.segmclass[id(s) ] = c\n",
    "\n",
    "        self.calc_trans_prob()\n",
    "\n",
    "\n",
    "    def load_model( self, basename ):\n",
    "        for c in range(self.numclass):\n",
    "            filename = basename + \"class%03d.npy\" % c\n",
    "            self.segm_in_class[c] = np.load( filename, allow_pickle=True)\n",
    "            self.update_gp( c )\n",
    "\n",
    "        self.trans_prob = np.load( basename+\"trans.npy\", allow_pickle=True )\n",
    "        self.trans_prob_bos = np.load( basename+\"trans_bos.npy\", allow_pickle=True )\n",
    "        self.trans_prob_eos = np.load( basename+\"trans_eos.npy\", allow_pickle=True )\n",
    "\n",
    "\n",
    "    def update_gp(self, c ):\n",
    "        datay = []\n",
    "        datax = []\n",
    "        for s in self.segm_in_class[c]:\n",
    "            datay += [ y for y in s ]\n",
    "            datax += range(len(s))\n",
    "\n",
    "        self.gps[c].learn( datax, datay )\n",
    "\n",
    "\n",
    "    def calc_emission_logprob( self, c, segm ):\n",
    "        gp = self.gps[c]\n",
    "        slen = len(segm)\n",
    "\n",
    "        if len(segm) > 2:\n",
    "            log_plen = (slen*math.log(self.AVE_LEN) + (-self.AVE_LEN)*math.log(math.e)) - (sum(np.log(np.arange(1,slen+1))))\n",
    "            p = gp.calc_lik( np.arange(len(segm), dtype=np.float) , segm )\n",
    "            return p + log_plen\n",
    "        else:\n",
    "            return math.log(1.0e-100)\n",
    "\n",
    "    def save_model(self, basename ):\n",
    "        if not os.path.exists(basename):\n",
    "            os.mkdir( basename )\n",
    "\n",
    "        for n,segm in enumerate(self.segments):\n",
    "            classes = []\n",
    "            cut_points = []\n",
    "            for s in segm:\n",
    "                c = self.segmclass[id(s)]\n",
    "                classes += [ c for i in range(len(s)) ]\n",
    "                cut_points += [0] * len(s)\n",
    "                cut_points[-1] = 1\n",
    "            np.savetxt( basename+\"segm%03d.txt\" % n, np.vstack([classes,cut_points]).T, fmt=str(\"%d\") )\n",
    "\n",
    "        for c in range(len(self.gps)):\n",
    "            for d in range(self.dim):\n",
    "                plt.clf()\n",
    "                for data in self.segm_in_class[c]:\n",
    "                    if self.dim==1:\n",
    "                        plt.plot( range(len(data)), data, \"o-\" )\n",
    "                    else:\n",
    "                        plt.plot( range(len(data[:,d])), data[:,d], \"o-\" )\n",
    "                    plt.ylim( -1, 1 )\n",
    "                plt.savefig( basename+\"class%03d_dim%03d.png\" % (c, d) )\n",
    "                plt.close()\n",
    "\n",
    "        np.save( basename + \"trans.npy\" , self.trans_prob  )\n",
    "        np.save( basename + \"trans_bos.npy\" , self.trans_prob_bos )\n",
    "        np.save( basename + \"trans_eos.npy\" , self.trans_prob_eos )\n",
    "        np.save( basename + \"all_class.npy\", self.segm_in_class[c])\n",
    "\n",
    "        for c in range(self.numclass):\n",
    "            np.save( basename+\"class%03d.npy\" % c, self.segm_in_class[c] )\n",
    "\n",
    "        return self.numclass\n",
    "\n",
    "\n",
    "    def forward_filtering(self, d ):\n",
    "        T = len(d)\n",
    "        log_a = np.log( np.zeros( (len(d), self.MAX_LEN, self.numclass) )  + 1.0e-100 ) \n",
    "        valid = np.zeros( (len(d), self.MAX_LEN, self.numclass) ) \n",
    "        z = np.ones( T )\n",
    "\n",
    "        for t in range(T):\n",
    "            for k in range(self.MIN_LEN,self.MAX_LEN,self.SKIP_LEN):\n",
    "                if t-k<0:\n",
    "                    break\n",
    "\n",
    "                segm = d[t-k:t+1]\n",
    "                for c in range(self.numclass):\n",
    "                    out_prob = self.calc_emission_logprob( c, segm )\n",
    "                    foward_prob = 0.0\n",
    "\n",
    "                    tt = t-k-1\n",
    "                    if tt>=0:\n",
    "                        foward_prob = logsumexp( log_a[tt,:,:] + z[tt] + np.log(self.trans_prob[:,c]) ) + out_prob\n",
    "                    else:\n",
    "                        foward_prob = out_prob + math.log(self.trans_prob_bos[c])\n",
    "\n",
    "                    if t==T-1:\n",
    "                        foward_prob += math.log(self.trans_prob_eos[c])\n",
    "\n",
    "                    log_a[t,k,c] = foward_prob\n",
    "                    valid[t,k,c] = 1.0\n",
    "                    if math.isnan(foward_prob):\n",
    "                        print( \"a[t=%d,k=%d,c=%d] became NAN!!\" % (t,k,c) )\n",
    "                        sys.exit(-1)\n",
    "\n",
    "            if t-self.MIN_LEN>=0:\n",
    "                z[t] = logsumexp( log_a[t,:,:] )\n",
    "                log_a[t,:,:] -= z[t]\n",
    "\n",
    "        return np.exp(log_a)*valid\n",
    "\n",
    "\n",
    "    def sample_idx(self, prob ):\n",
    "        accm_prob = [0,] * len(prob)\n",
    "        for i in range(len(prob)):\n",
    "            accm_prob[i] = prob[i] + accm_prob[i-1]\n",
    "\n",
    "        rnd = random.random() * accm_prob[-1]\n",
    "        for i in range(len(prob)):\n",
    "            if rnd <= accm_prob[i]:\n",
    "                return i\n",
    "\n",
    "\n",
    "    def backward_sampling(self, a, d):\n",
    "        T = a.shape[0]\n",
    "        t = T-1\n",
    "\n",
    "        segm = []\n",
    "        segm_class = []\n",
    "\n",
    "        c = -1\n",
    "        while True:\n",
    "            if t==T-1:\n",
    "                transp = self.trans_prob_eos\n",
    "            else:\n",
    "                transp = self.trans_prob[:,c]\n",
    "            \n",
    "            idx = self.sample_idx( (a[t]*transp).reshape( self.MAX_LEN*self.numclass ))\n",
    "\n",
    "            k = int(idx/self.numclass)\n",
    "            c = idx % self.numclass\n",
    "\n",
    "            if t-k-1<=0:\n",
    "                s = d[0:t+1]\n",
    "            else:\n",
    "                s = d[t-k:t+1]\n",
    "\n",
    "            segm.insert( 0, s )\n",
    "            segm_class.insert( 0, c )\n",
    "\n",
    "            t = t-k-1\n",
    "\n",
    "            if t<=0:\n",
    "                break\n",
    "\n",
    "        return segm, segm_class\n",
    "\n",
    "\n",
    "    def calc_trans_prob( self ):\n",
    "        self.trans_prob = np.zeros( (self.numclass,self.numclass) )\n",
    "        self.trans_prob_bos = np.zeros( self.numclass )\n",
    "        self.trans_prob_eos = np.zeros( self.numclass )\n",
    "\n",
    "        for n,segm in enumerate(self.segments):\n",
    "            if id(segm[0]) in self.segmclass:\n",
    "                c_begin = self.segmclass[ id(segm[0]) ]\n",
    "                self.trans_prob_bos[c_begin]+=1\n",
    "\n",
    "            if id(segm[-1]) in self.segmclass:\n",
    "                c_end = self.segmclass[ id(segm[-1]) ]\n",
    "                self.trans_prob_eos[c_end]+=1\n",
    "\n",
    "            for i in range(1,len(segm)):\n",
    "                try:\n",
    "                    cc = self.segmclass[ id(segm[i-1]) ]\n",
    "                    c = self.segmclass[ id(segm[i]) ]\n",
    "                except KeyError:\n",
    "\n",
    "                    continue\n",
    "                self.trans_prob[cc,c] += 1\n",
    "\n",
    "        self.trans_prob_bos += self.alpha * self.beta\n",
    "        self.trans_prob_eos += self.alpha * self.beta\n",
    "\n",
    "        for c in range(self.numclass):\n",
    "            self.trans_prob[c,:] += self.alpha * self.beta\n",
    "\n",
    "        self.trans_prob = self.trans_prob / self.trans_prob.sum(1).reshape(self.numclass,1)\n",
    "        self.trans_prob_bos = self.trans_prob_bos / np.sum( self.trans_prob_bos )\n",
    "        self.trans_prob_eos = self.trans_prob_eos / np.sum( self.trans_prob_eos )\n",
    "\n",
    "\n",
    "    def sample_num_states(self):\n",
    "\n",
    "        # calculate u\n",
    "        u = []\n",
    "        for n,segm in enumerate(self.segments):\n",
    "            c = self.segmclass[ id(segm[0]) ]\n",
    "            p = self.trans_prob_bos[c]\n",
    "            u.append( random.random() * p )\n",
    "\n",
    "            c = self.segmclass[ id(segm[-1]) ]\n",
    "            p = self.trans_prob_eos[c]\n",
    "            u.append( random.random() * p )\n",
    "\n",
    "            for i in range(1,len(segm)):\n",
    "                cc = self.segmclass[ id(segm[i-1]) ]\n",
    "                c = self.segmclass[ id(segm[i]) ]\n",
    "                p = self.trans_prob[cc,c]\n",
    "                u.append( random.random() * p )\n",
    "\n",
    "        # remove \n",
    "        beta = list( self.beta )\n",
    "        for c in range(self.numclass)[::-1]:\n",
    "            if len(self.segm_in_class[c])==0:\n",
    "                self.numclass -= 1\n",
    "                self.gps.pop()\n",
    "                self.segm_in_class.pop()\n",
    "                beta[-2] += beta[-1]\n",
    "                beta.pop()\n",
    "                #print (\"pop!\")\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        u_min = np.min( u )\n",
    "\n",
    "        N = 0\n",
    "        for c in range(self.numclass):\n",
    "            N += len(self.segm_in_class[c])\n",
    "\n",
    "        while self.alpha*beta[-1]/N > u_min:\n",
    "            stick_len = beta[-1]\n",
    "            rnd = np.random.beta(1,self.gamma)\n",
    "            beta[-1] = stick_len * rnd\n",
    "            beta.append( stick_len * (1-rnd) )\n",
    "            self.numclass += 1\n",
    "            self.gps.append( GPMD(self.dim) )\n",
    "            self.segm_in_class.append([])\n",
    "\n",
    "        self.beta = np.array( beta )\n",
    "\n",
    "        self.all_numclass.append(self.numclass)\n",
    "    \n",
    "    \n",
    "    # If list.remove( elem ), ValueError.\n",
    "    def remove_ndarray(self, lst, elem ):\n",
    "        l = len(elem)\n",
    "        for i,e in enumerate(lst):\n",
    "            if len(e)!=l:\n",
    "                continue\n",
    "            if (e==elem).all():\n",
    "                lst.pop(i)\n",
    "                return\n",
    "        raise ValueError( \"ndarray is not found!!\" )\n",
    "\n",
    "    def learn(self):\n",
    "        if self.is_initialized==False:\n",
    "            # learn GP\n",
    "            for i in range(len(self.segments)):\n",
    "                for s in self.segments[i]:\n",
    "                    c = self.segmclass[id(s)]\n",
    "                    self.segm_in_class[c].append( s )\n",
    "\n",
    "            # learn each classes\n",
    "            for c in range(self.numclass):\n",
    "                self.update_gp( c )\n",
    "\n",
    "            self.is_initialized = True\n",
    "\n",
    "        self.update(True)\n",
    "\n",
    "    def recog(self):\n",
    "        self.update(False)\n",
    "\n",
    "    def update(self, learning_phase=True ):\n",
    "\n",
    "        for i in range(len(self.segments)):\n",
    "            if learning_phase:\n",
    "                print (\"slice sampling\")\n",
    "                self.sample_num_states()\n",
    "            \n",
    "            d = self.data[i]\n",
    "            segm = self.segments[i]\n",
    "\n",
    "            for s in segm:\n",
    "                c = self.segmclass[id(s)]\n",
    "                self.segmclass.pop( id(s) )\n",
    "\n",
    "                if learning_phase:\n",
    "                    # update parameter\n",
    "                    self.remove_ndarray( self.segm_in_class[c], s )\n",
    "\n",
    "            if learning_phase:\n",
    "                # update GP\n",
    "                for c in range(self.numclass):\n",
    "                    self.update_gp( c )\n",
    "\n",
    "                # update transition probability\n",
    "                self.calc_trans_prob()\n",
    "\n",
    "            start = time.clock()\n",
    "            print( \"forward...\", end=\"\")\n",
    "            a = self.forward_filtering( d )\n",
    "\n",
    "            print( \"backward...\", end=\"\" )\n",
    "            segm, segm_class = self.backward_sampling( a, d )\n",
    "            print( time.clock()-start, \"sec\" )\n",
    "\n",
    "            print( \"Number of classified segments: [\", end=\"\")\n",
    "            for s in self.segm_in_class:\n",
    "                print( len(s), end=\" \" )\n",
    "            print( \"]\" )\n",
    "\n",
    "\n",
    "            self.segments[i] = segm\n",
    "\n",
    "            for s,c in zip( segm, segm_class ):\n",
    "                self.segmclass[id(s)] = c\n",
    "\n",
    "                # update parameter\n",
    "                if learning_phase:\n",
    "                    self.segm_in_class[c].append(s)\n",
    "\n",
    "            if learning_phase:\n",
    "                # update GP\n",
    "                for c in range(self.numclass):\n",
    "                    self.update_gp( c )\n",
    "\n",
    "                # update transition probability\n",
    "                self.calc_trans_prob()\n",
    "        return\n",
    "\n",
    "\n",
    "    def calc_lik(self, last=False):\n",
    "        liks = 0\n",
    "        mus_all = []\n",
    "        sigmas_all = []\n",
    "\n",
    "        for segm in self.segments:\n",
    "            # last\n",
    "            if last != False:\n",
    "              mus = [[] for i in range(self.dim)]\n",
    "              sigmas = [[] for i in range(self.dim)]\n",
    "\n",
    "            for n, s in enumerate(segm):\n",
    "                c = self.segmclass[id(s)]\n",
    "                liks += self.gps[c].calc_lik( np.arange(len(s),dtype=np.float) , np.array(s) )\n",
    "                \n",
    "                # last\n",
    "                if last != False:\n",
    "                  lik, mu, sig = self.gps[c].calc_lik( np.arange(len(s), dtype=np.float) , s , last)\n",
    "                  if n == 0:\n",
    "                    for dd in range(self.dim):\n",
    "                        mus[dd] = mu[dd]\n",
    "                        sigmas[dd] = sig[dd]\n",
    "                  else:\n",
    "                    for dd in range(self.dim):\n",
    "                        mus[dd] = np.concatenate([mus[dd], mu[dd]])\n",
    "                        sigmas[dd] = np.concatenate([sigmas[dd], sig[dd]])\n",
    "\n",
    "                  liks += lik\n",
    "\n",
    "            # last\n",
    "            if last != False:\n",
    "              mus_all.append((np.array(mus).T).astype(np.float32))\n",
    "              sigmas_all.append(np.log((np.array(sigmas).T).astype(np.float32)))\n",
    "\n",
    "        #last\n",
    "        if last != False:\n",
    "          return liks, mus_all, sigmas_all\n",
    "        else:\n",
    "          return liks\n",
    "\n",
    "    \n",
    "    def get_num_class(self):\n",
    "        n = 0\n",
    "        for c in range(self.numclass):\n",
    "            if len(self.segm_in_class[c])!=0:\n",
    "                n += 1\n",
    "        return n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w21E05WtWt66"
   },
   "source": [
    "### main_segm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ws1Ve9DCWv1q"
   },
   "outputs": [],
   "source": [
    "def learn( zs, savedir, dim, gamma, eta, initial_class ):\n",
    "    gpsegm = GPSegmentation( dim, gamma, eta, initial_class)\n",
    "\n",
    "    gpsegm.load_data( zs )\n",
    "    liks = []\n",
    "\n",
    "    start_time = time.time()\n",
    "    #iteration (default: 10)\n",
    "    for it in range( 8 ):\n",
    "        print( \"-----\", it, \"-----\" )\n",
    "        gpsegm.learn()\n",
    "        numclass = gpsegm.save_model( savedir )\n",
    "        print( \"lik =\", gpsegm.calc_lik() )\n",
    "        liks.append(gpsegm.calc_lik())\n",
    "    #print (\"liks: \",liks)\n",
    "    print ('%.2f[sec]'%(time.time()-start_time))\n",
    "    \n",
    "    #plot liks\n",
    "    plt.clf()\n",
    "    plt.plot( range(len(liks)), liks )\n",
    "    plt.savefig( os.path.join( savedir,\"liks.png\") )\n",
    "\n",
    "    lik, mu, sigma = gpsegm.calc_lik(last=True)\n",
    "    return numclass, np.array(mu), np.array(sigma)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BtlVr6eDTiiq"
   },
   "source": [
    "### main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1MZ7KwpjVAzw"
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    hidden_dim = [40,20,20,40]\n",
    "    latent_dim= 3\n",
    "    \n",
    "    #weight of KLD\n",
    "    kld_weight = 0.9\n",
    "    #number of learn of vae in an iteration \n",
    "    epochs = 10\n",
    "    #mutual learning loop (VAE and HDP-GP-HSMM)\n",
    "    iteration = 10\n",
    "\n",
    "    data_ = []\n",
    "    batch_sizes = []\n",
    "    logvar_priors = []\n",
    "    mu_priors = []\n",
    "\n",
    "    #pathの変更をしてください．\n",
    "    files =  [ \"dance%03d.txt\" % j for j in range(4) ]\n",
    "    for f in files:\n",
    "      y = np.loadtxt(f, dtype=np.float)[::15]\n",
    "      #print (len(y))\n",
    "      data_.append( y )\n",
    "      batch_sizes.append( int(len(y)/4) )\n",
    "\n",
    "      logvar_priors.append( np.array( np.zeros( (len(y),latent_dim) ), dtype='float32' ) )\n",
    "      mu_priors.append( np.array( np.zeros( (len(y),latent_dim) ), dtype='float32' ) )\n",
    "\n",
    "    input_dim=len(data_[0][0])\n",
    "\n",
    "    #HDP-GP-HSMM parameters\n",
    "    gamma = 2.0\n",
    "    eta = 5.0\n",
    "    initial_class = 1\n",
    "\n",
    "    #define VAE\n",
    "    vae = Variational_Auto_Encoder(input_dim, hidden_dim, latent_dim, kld_weight, epochs)\n",
    "    vae.compile()\n",
    "\n",
    "    path = ('HVGH/')\n",
    "    #learn VAE and HSP-GP-HSMM\n",
    "    for ite in range(iteration):\n",
    "      print (\"*--------------iteration:%03d--------------*\"%ite)\n",
    "      zs = []\n",
    "      for n, data in enumerate(data_):\n",
    "        losses = []\n",
    "        #start_time = time.time()\n",
    "\n",
    "        for e in range(epochs):\n",
    "          idx = np.random.choice(range(0, len(data)), batch_sizes[n])\n",
    "          result = vae.learn(data[idx], logvar_priors[n][idx], mu_priors[n][idx], verbose=0)\n",
    "          losses.append(result.history['loss'])\n",
    "        \n",
    "        #print ('%.2f[sec]'%(time.time()-start_time))\n",
    "        #predicts\n",
    "        reconst, mu, sigma, z = vae.predict(data, logvar_priors[n], mu_priors[n], losses)\n",
    "        savepath = (path+'HVGHlearn/%03d/'%ite)\n",
    "        if not os.path.exists(savepath):\n",
    "          os.makedirs(savepath)\n",
    "        savepath_ = (savepath + 'data_%03d'%n)\n",
    "        vae.plot(data, reconst, mu, sigma, z, losses, savepath_)\n",
    "        print ('VAE learned', 'iteration:', ite, 'data:', n)\n",
    "\n",
    "        zs.append(np.array(mu))\n",
    "        np.savetxt(savepath_+'_z.txt', mu)\n",
    "        \n",
    "      #vae.save_weights(savepath+'vae_weights.hdf5')\n",
    "      vae.VAE.save_weights(savepath+'vae_weights.hdf5')\n",
    "\n",
    "      # HDP-GP-HSMM\n",
    "      #learn\n",
    "      z_dim = len(zs[0][0])\n",
    "      recog_initial_class, mu_priors, logvar_priors = learn( zs, savepath, z_dim, gamma, eta, initial_class )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V3NIpYNyTTjV"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chengyu/anaconda3/envs/ml/lib/python3.7/site-packages/ipykernel_launcher.py:20: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "2022-04-08 15:32:30.664428: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2022-04-08 15:32:30.689827: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: \n",
      "pciBusID: 0000:17:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2022-04-08 15:32:30.690287: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 1 with properties: \n",
      "pciBusID: 0000:65:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.91GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2022-04-08 15:32:30.690471: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-04-08 15:32:30.691741: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2022-04-08 15:32:30.693306: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2022-04-08 15:32:30.693539: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2022-04-08 15:32:30.694866: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-04-08 15:32:30.695603: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-04-08 15:32:30.695685: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory\n",
      "2022-04-08 15:32:30.695692: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1592] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-04-08 15:32:30.695987: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n",
      "2022-04-08 15:32:30.718820: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3499910000 Hz\n",
      "2022-04-08 15:32:30.719419: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5578a1061550 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2022-04-08 15:32:30.719439: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2022-04-08 15:32:30.838988: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5578a0ea45f0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2022-04-08 15:32:30.839014: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 1080 Ti, Compute Capability 6.1\n",
      "2022-04-08 15:32:30.839020: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): NVIDIA GeForce GTX 1080 Ti, Compute Capability 6.1\n",
      "2022-04-08 15:32:30.839195: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-04-08 15:32:30.839206: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
      "WARNING:tensorflow:Output encoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to encoder.\n",
      "WARNING:tensorflow:Output encoder_1 missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to encoder_1.\n",
      "WARNING:tensorflow:Output encoder_2 missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to encoder_2.\n",
      "*--------------iteration:000--------------*\n",
      "VAE learned iteration: 0 data: 0\n",
      "VAE learned iteration: 0 data: 1\n",
      "VAE learned iteration: 0 data: 2\n",
      "VAE learned iteration: 0 data: 3\n",
      "----- 0 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chengyu/anaconda3/envs/ml/lib/python3.7/site-packages/ipykernel_launcher.py:34: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "/home/chengyu/anaconda3/envs/ml/lib/python3.7/site-packages/ipykernel_launcher.py:7: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  import sys\n",
      "/home/chengyu/anaconda3/envs/ml/lib/python3.7/site-packages/ipykernel_launcher.py:8: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slice sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chengyu/anaconda3/envs/ml/lib/python3.7/site-packages/ipykernel_launcher.py:351: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "/home/chengyu/anaconda3/envs/ml/lib/python3.7/site-packages/ipykernel_launcher.py:83: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward...backward...1.6298010000000005 sec\n",
      "Number of classified segments: [27 0 0 0 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chengyu/anaconda3/envs/ml/lib/python3.7/site-packages/ipykernel_launcher.py:357: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slice sampling\n",
      "forward...backward...1.6948639999999955 sec\n",
      "Number of classified segments: [28 0 0 0 0 ]\n",
      "slice sampling\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1283045/451043146.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_1283045/3881183856.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     70\u001b[0m       \u001b[0;31m#learn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m       \u001b[0mz_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m       \u001b[0mrecog_initial_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu_priors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogvar_priors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mzs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msavepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_class\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_1283045/947459047.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(zs, savedir, dim, gamma, eta, initial_class)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;36m8\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m\"-----\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"-----\"\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mgpsegm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mnumclass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgpsegm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0msavedir\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m\"lik =\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpsegm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalc_lik\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_1283045/1171512017.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    318\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_initialized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrecog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_1283045/1171512017.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, learning_phase)\u001b[0m\n\u001b[1;32m    344\u001b[0m                 \u001b[0;31m# update GP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumclass\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_gp\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m                 \u001b[0;31m# update transition probability\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_1283045/1171512017.py\u001b[0m in \u001b[0;36mupdate_gp\u001b[0;34m(self, c)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0mdatax\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mdatax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatay\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_1283045/607409304.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__gp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__gp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m_cython_magic_5ea48c245d85af0c315f235b9af061d0.pyx\u001b[0m in \u001b[0;36m_cython_magic_5ea48c245d85af0c315f235b9af061d0.GP.learn\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36minv\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml/lib/python3.7/site-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36minv\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m    543\u001b[0m     \u001b[0msignature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'D->D'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misComplexType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'd->d'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m     \u001b[0mextobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_linalg_error_extobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_raise_linalgerror_singular\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m     \u001b[0mainv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_umath_linalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    546\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mainv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "HVGH",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
